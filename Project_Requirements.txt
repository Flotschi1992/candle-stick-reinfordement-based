
-- What We Want to Do ----------------------------------------------------------
Build a self-adapting AI that predicts the next candlestick (or its direction) 
using reinforcement learning (RL). The model will learn from historical data and 
continue adapting as new data arrives. For the candlestich we want to use the 
Dow Jones us30 Index. Idea would be, each day (or like each 
evening):
 - it grabs the last valid data, 
 - compares it with what was estimated and adapts itself
 - gives a prediction of tomorrows data


-- Tech Stack ------------------------------------------------------------------

Environment: GitHub Codespaces
Language: Python
Libraries:
    Stable Baselines3 (RL algorithms like PPO)
    Gymnasium (custom trading environment)
    PyTorch (for neural networks, LSTM/Transformer)
    Pandas, NumPy (data handling)
    Matplotlib/Plotly (visualization)

-- Goal -------------------------------------------------------------------------
--> Main Focus: Creation of RL project to be able to show potential employes some 
    skills!!
--> Learn by doing. It is important to implement everythin step by step to be 
    able to learn
    --> we wanted to use the daily candlestick from the Dow Jones us30 Index
    --> we wanted to get the data from yahoo
--> Short-term:
    Get the needed data, view it and verify it
    Create an RL agent that:
        Takes recent candlestick data as state.
        Predicts next candle or decides an action (buy/sell/hold).
        Learns from rewards (accuracy or simulated profit).
        Adapts continuously.
    Idea would be to train it with a certain amount of data, and keep some to play a bit 
    with the scenario, like decribed above. 


-- Where we are right now -------------------------------------------------------------
1.) Get GitHub Codespace up and running
2.) Install all packages from requirements.txt
3.) create a data_import.ipynb
    a.) Get all data between 01jan200 - 31dez2024 from Alpha Vantage -> DIA
    b.) Have a first look at the data 
    c.) data was cleaned and stored in data/clean_data.csv
    d.) basic vaisualisation was done 
4.) created notebooks/rl_environment.ipynb with Gymnasium environment skeleton  
    a.) create a trading env class
    b.) get the data and normalize it
    c.) train the model
    d.) test the model

What we should do next:
    -> understand the data
        -> understand the input data, to be able to better
        -> understandthe output data, especially in
        -> the context of normalisation, and
        -> what I really would have
            -> won, or
            -> lost, or
            -> what my maximal loss would be (how deep do I have to grab in the pocket)
               (depending on my stake)

-- Folderstructure -------------------------------------------------------------------

tree
.
├── .devcontainer
│   └── devcontainer.json
├── .env
├── .gitignore
├── CheatSheet.txt
├── LICENSE
├── Project_Requirements.txt
├── README.md
├── data
│   └── Candlestick_01jan2000_31dec2024.csv
├── models
│   └── scaler.pkl
├── notebooks
│   ├── data_import.ipynb
│   └── rl_environment.ipynb
└── requirements.txt