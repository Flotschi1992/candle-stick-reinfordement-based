
-- What We Want to Do ----------------------------------------------------------
Build a self-adapting AI that predicts the next candlestick (or its direction) using reinforcement learning (RL). The model will learn from historical data and continue adapting as new data arrives.

-- Tech Stack ------------------------------------------------------------------

Environment: GitHub Codespaces
Language: Python
Libraries:

Stable Baselines3 (RL algorithms like PPO)
Gymnasium (custom trading environment)
PyTorch (for neural networks, LSTM/Transformer)
Pandas, NumPy (data handling)
Matplotlib/Plotly (visualization)

-- Goal -------------------------------------------------------------------------

--> Short-term:
    Create an RL agent that:

    Takes recent candlestick data as state.
    Predicts next candle or decides an action (buy/sell/hold).
    Learns from rewards (accuracy or simulated profit).
    Adapts continuously.

--> Long-term:
    Build a framework that can transfer this adaptive learning concept to other domains (e.g., robotics).

-- What to be done -------------------------------------------------------------
1.) Get GitHub Codespace up and running
2.) Create a basic file structure
1.) Get the data, have a look at it and clean it up

