{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fc1c8dc",
   "metadata": {},
   "source": [
    "## Custom Gymnasium Enviroment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7df1201",
   "metadata": {},
   "source": [
    "Import whats needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f31a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we convert the jupiter file to a python script since it is easier to handle \n",
    "!jupyter nbconvert --to script --output rl_environment rl_environment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supporting_classes import TradingEnv, OHLCScaler\n",
    "import joblib\n",
    "\n",
    "# Load raw data\n",
    "data = pd.read_csv('../data/Candlestick_01nov1999_28oct2025.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Split into train/test\n",
    "split_idx  = int(len(data) * 0.8)\n",
    "train_data = data.iloc[:split_idx]\n",
    "test_data  = data.iloc[split_idx:]\n",
    "\n",
    "# Fit OHLCScaler on training data\n",
    "scaler = OHLCScaler(train_data)\n",
    "\n",
    "# Transform train and test data\n",
    "scaled_train_df = scaler.transform(train_data)\n",
    "scaled_test_df  = scaler.transform(test_data)\n",
    "\n",
    "# Save scaler for future use\n",
    "joblib.dump(scaler, '../models/scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e621c",
   "metadata": {},
   "source": [
    "Understand the Data better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb59fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at the original data\n",
    "print(data.head()) # print the first few rows of the original data\n",
    "print(\"...\")\n",
    "print(data.tail())  # print the last few rows of the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at the scaled training data\n",
    "print(scaled_train_df.head()) # print the first few rows of the scaled training data\n",
    "print(\"...\")\n",
    "print(scaled_test_df.tail())  # print the last few rows of the scaled test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9673048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view both datasets as candle-stick charts, lets say one month each\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "\n",
    "FIG_SCALE = 0.5\n",
    "\n",
    "plot_data_org = data.loc['2000-03-01':'2000-03-31']\n",
    "plot_data_nor = scaled_train_df.loc['2000-03-01':'2000-03-31']\n",
    "\n",
    "mpf.plot(plot_data_org, type='candle', volume=False, title='Scaled Original Data', style='yahoo', figscale=FIG_SCALE)\n",
    "mpf.plot(plot_data_nor, type='candle', volume=False, title='Scaled Normalized Data', style='yahoo', figscale=FIG_SCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4327f34b",
   "metadata": {},
   "source": [
    "# PPO training and evaluation code\n",
    "Now its time to get the data and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supporting_classes import TradingEnv\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Create environment\n",
    "env = TradingEnv(scaled_train_df, window_size=50)\n",
    "\n",
    "\n",
    "# Define PPO model with tuned hyperparameters for trading\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",                # Use a Multi-Layer Perceptron policy\n",
    "    env,                        # Pass the trading environment\n",
    "    learning_rate=0.0003,       # Lower learning rate for more stable updates\n",
    "    n_steps=8192,               # Number of steps per rollout (larger for stability)\n",
    "    batch_size=256,             # Batch size for gradient updates\n",
    "    n_epochs=10,                # Number of epochs per update\n",
    "    gamma=0.99,                 # Discount factor (shorter horizon for trading)\n",
    "    gae_lambda=0.95,            # GAE parameter for advantage estimation\n",
    "    clip_range=0.2,             # PPO clipping range\n",
    "    ent_coef=0.05,              # Encourage exploration\n",
    "    vf_coef=0.5,                # Weight for value function loss\n",
    "    max_grad_norm=0.5,          # Gradient clipping for stability\n",
    "    normalize_advantage=True,   # Helps with stability\n",
    "    policy_kwargs=dict(net_arch=[256, 256]),  # Larger network for complex patterns\n",
    "    target_kl=0.03,             # ensures stability even with aggressive updates\n",
    "    verbose=1                   # Print training logs\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=100_000)        # train the model for 100,000 timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8151397e",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da4cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# craete a file name depending on the last trained date\n",
    "filenPath = f\"../models/ppo_trading_{scaled_train_df.index[split_idx - 1].strftime('%Y_%m_%d')}\"\n",
    "\n",
    "print(scaled_train_df.tail()  )\n",
    "\n",
    "# save the trained model\n",
    "print(f\"Saving model as {filenPath}\")\n",
    "model.save(filenPath)         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0a9d92",
   "metadata": {},
   "source": [
    "# Initial Testing\n",
    "Now let's test the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2fa4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-Umgebung erstellen\n",
    "test_env = TradingEnv(scaled_test_df, window_size=50)\n",
    "\n",
    "# Evaluation\n",
    "obs, info = test_env.reset()                    # reset the environment to start a new episode\n",
    "total_reward = 0                                # initialize total reward\n",
    "steps = 0                                       # initialize step counter\n",
    "\n",
    "while True:\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, _, _ = test_env.step(action)\n",
    "    total_reward += reward\n",
    "    steps += 1\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print(f\"Total Reward on Test Data: {total_reward:.4f}\")\n",
    "print(f\"Steps: {steps}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
