{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a99a8be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook supporting_classes.ipynb to script\n",
      "[NbConvertApp] Writing 6723 bytes to supporting_classes.py\n"
     ]
    }
   ],
   "source": [
    "# here we convert the jupiter file to a python script since it is easier to handle \n",
    "!jupyter nbconvert --to script --output supporting_classes supporting_classes.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1aa576",
   "metadata": {},
   "source": [
    "# TradingEnv Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75e3d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gymnasium as gym         # Gymnasium is a library for building RL environments\n",
    "                                # It provides a standard interface so RL algorithms (like PPO from Stable Baselines3) can interact with your environment.\n",
    "from gymnasium import spaces    # spaces defines the action space and observation space for your environment\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, data: pd.DataFrame, window_size=50):\n",
    "        super().__init__()                              # initialize the base class\n",
    "        self.data = data.reset_index(drop=True)         # reset index for easier slicing and store it in self.data\n",
    "        self.window_size = window_size                  # number of previous candles to include in the observation\n",
    "        self.current_step = window_size                 # start after the initial window\n",
    "\n",
    "        # Observation: last N candles (OHLC + Volume)\n",
    "        self.observation_space = spaces.Box(            # description of the observation space is given\n",
    "            low=-np.inf, high=np.inf,                   # low and high values for each element in the observation are unbounded / infinite\n",
    "            shape=(window_size, self.data.shape[1]),    # shape of the observation (window_size rows, number of features columns)\n",
    "            dtype=np.float32                            # data type of the observation elements\n",
    "        )\n",
    "        # Actions: 0 = Hold, 1 = Buy, 2 = Sell\n",
    "        self.action_space = spaces.Discrete(3)          # actually, there is not much we can do\n",
    "\n",
    "    def reset(self, seed=None, options=None):           # reset the environment to initial state\n",
    "        super().reset(seed=seed)                        # call the base class reset method\n",
    "        self.current_step = self.window_size            # bring current step back to initial position\n",
    "        return self._get_observation(), {}              # return the last known observation and an empty info dict\n",
    "                                                        #   -> dict can be used to pass additional information like debugging info                                               \n",
    "\n",
    "    def step(self, action):                             # do one step of the training\n",
    "        reward = self._calculate_reward(action)         # calculate reward based on action taken - in the end the |profit/loss|\n",
    "        self.current_step += 1                          # move to the next time step\n",
    "        done = self.current_step >= len(self.data) - 1  # episode is done if we reach the end of the data\n",
    "        return self._get_observation(), reward, done, False, {} \n",
    "\n",
    "    def _get_observation(self):\n",
    "        obs = self.data.iloc[self.current_step - self.window_size:self.current_step].values # Return last N rows as observation \":\" is NOT a division\n",
    "        return obs.astype(np.float32)                   # return the last <windwow_size> observations as float32 numpy array\n",
    "\n",
    "    def _calculate_reward(self, action, hold_threshold=0.1, transaction_cost=0.01):\n",
    "        start_price = self.data['Open'].iloc[self.current_step]\n",
    "        end_price = self.data['Close'].iloc[self.current_step]\n",
    "        price_diff_pct = (end_price - start_price) / start_price * 100\n",
    "\n",
    "        # Determine correct action\n",
    "        if abs(price_diff_pct) <= hold_threshold:\n",
    "            correct_action = 0  # HOLD\n",
    "        elif price_diff_pct > hold_threshold:\n",
    "            correct_action = 1  # CALL\n",
    "        else:\n",
    "            correct_action = 2  # PUT\n",
    "\n",
    "        # Base reward\n",
    "        if action == correct_action:\n",
    "            reward = 0.7 if action == 0 else 1.0\n",
    "        else:\n",
    "            reward = -0.2 if action == 0 else -0.5\n",
    "\n",
    "        # Bonus for magnitude (only if correct and not HOLD)\n",
    "        if action == correct_action and action != 0:\n",
    "            bonus = np.clip(abs(price_diff_pct) / 100, 0, 1.0)  # max bonus = 1.0\n",
    "            reward += bonus\n",
    "\n",
    "        # Transaction cost penalty for CALL/PUT\n",
    "        if action in [1, 2]:\n",
    "            reward -= transaction_cost\n",
    "\n",
    "        return reward\n",
    "\n",
    "\n",
    "    \n",
    "    def render(self, action=None, reward=None):  # render the current state of the environment\n",
    "        msg = f\"Step: {self.current_step}, Close Price: {self.data['Close'].iloc[self.current_step]}\"\n",
    "        if action is not None:  # if an action was taken, include it in the message\n",
    "            msg += f\", Action: {action}\"\n",
    "        if reward is not None:  # if a reward was given, include it in the message\n",
    "            msg += f\", Reward: {reward:.4f}\"\n",
    "        print(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fee1ba",
   "metadata": {},
   "source": [
    "# OHLCScaler Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12b98abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since StandardSkaler works column-wise, and OHLC value should have the SAME scaling, we have to do a bit of manual work here\n",
    "class OHLCScaler:\n",
    "    def __init__(self, train_df: pd.DataFrame):                     # with the init fct the hole dataset is given in for Open, High, \n",
    "                                                                    # Low, Close and Volume\n",
    "        self.columns_ohlc = ['Open', 'High', 'Low', 'Close']        # all OHLC columns in one mean/std\n",
    "        self.column_volume = 'Volume'                               # Volume column in a 2nd mean/std\n",
    "\n",
    "        ohlc_values = train_df[self.columns_ohlc].values.flatten()  # get all given OHLC values from all columns \n",
    "        self.mean_ohlc = np.mean(ohlc_values)                       # calculate mean for OHLC values\n",
    "        self.std_ohlc = np.std(ohlc_values)                         # calculate std for OHLC values\n",
    "\n",
    "        volume_values = train_df[self.column_volume].values         # same for all Volume values\n",
    "        self.mean_volume = np.mean(volume_values)\n",
    "        self.std_volume = np.std(volume_values)\n",
    "\n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:      # the transform method scales a hole given dataframe in the form Open, \n",
    "                                                                # High, Low, Close and Volume\n",
    "        df_scaled = df.copy()\n",
    "        for col in self.columns_ohlc:\n",
    "            df_scaled[col]            = (df_scaled[col]                - self.mean_ohlc)   / self.std_ohlc\n",
    "        df_scaled[self.column_volume] = (df_scaled[self.column_volume] - self.mean_volume) / self.std_volume\n",
    "        return df_scaled\n",
    "    \n",
    "    def re_transform(self, normalized_gain: float, normalized_price: float) -> tuple:\n",
    "        real_price = normalized_price * self.std_ohlc + self.mean_ohlc\n",
    "        real_gain  = normalized_gain  * self.std_ohlc # for the gain the mean μ is not needed -> −μ−(−μ)=−μ+μ=0\n",
    "        return real_gain, real_price"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
